{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ-sOptoyawI",
        "outputId": "dfc477a0-f6eb-4b8d-da08-67f275c0a8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution Before KMeansSMOTE:\n",
            " severity\n",
            "1.0    151\n",
            "4.0    124\n",
            "3.0    113\n",
            "2.0     32\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution After KMeansSMOTE:\n",
            " severity\n",
            "3.0    156\n",
            "4.0    155\n",
            "2.0    152\n",
            "1.0    151\n",
            "Name: count, dtype: int64\n",
            "Number of features remaining after LDA: 3\n",
            "KNN (3 neighbors) Accuracy: 0.7480\n",
            "KNN (3 neighbors) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.76      0.87      0.81        30\n",
            "         2.0       0.78      0.75      0.77        24\n",
            "         3.0       0.79      0.58      0.67        38\n",
            "         4.0       0.68      0.84      0.75        31\n",
            "\n",
            "    accuracy                           0.75       123\n",
            "   macro avg       0.75      0.76      0.75       123\n",
            "weighted avg       0.75      0.75      0.74       123\n",
            "\n",
            "KNN (3 neighbors) Confusion Matrix:\n",
            "[[26  2  2  0]\n",
            " [ 4 18  1  1]\n",
            " [ 4  1 22 11]\n",
            " [ 0  2  3 26]]\n",
            "KNN (5 neighbors) Accuracy: 0.7317\n",
            "KNN (5 neighbors) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.81      0.83      0.82        30\n",
            "         2.0       0.67      0.75      0.71        24\n",
            "         3.0       0.81      0.58      0.68        38\n",
            "         4.0       0.66      0.81      0.72        31\n",
            "\n",
            "    accuracy                           0.73       123\n",
            "   macro avg       0.74      0.74      0.73       123\n",
            "weighted avg       0.74      0.73      0.73       123\n",
            "\n",
            "KNN (5 neighbors) Confusion Matrix:\n",
            "[[25  4  1  0]\n",
            " [ 5 18  0  1]\n",
            " [ 1  3 22 12]\n",
            " [ 0  2  4 25]]\n",
            "Random Forest Accuracy: 0.7642\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.83      0.83      0.83        30\n",
            "         2.0       0.79      0.79      0.79        24\n",
            "         3.0       0.74      0.68      0.71        38\n",
            "         4.0       0.71      0.77      0.74        31\n",
            "\n",
            "    accuracy                           0.76       123\n",
            "   macro avg       0.77      0.77      0.77       123\n",
            "weighted avg       0.77      0.76      0.76       123\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            "[[25  4  1  0]\n",
            " [ 3 19  2  0]\n",
            " [ 2  0 26 10]\n",
            " [ 0  1  6 24]]\n",
            "AdaBoost Accuracy: 0.7561\n",
            "AdaBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.88      0.93      0.90        30\n",
            "         2.0       0.87      0.83      0.85        24\n",
            "         3.0       0.60      0.76      0.67        38\n",
            "         4.0       0.80      0.52      0.63        31\n",
            "\n",
            "    accuracy                           0.76       123\n",
            "   macro avg       0.79      0.76      0.76       123\n",
            "weighted avg       0.77      0.76      0.75       123\n",
            "\n",
            "AdaBoost Confusion Matrix:\n",
            "[[28  0  2  0]\n",
            " [ 1 20  3  0]\n",
            " [ 3  2 29  4]\n",
            " [ 0  1 14 16]]\n",
            "Gradient Boosting Accuracy: 0.7236\n",
            "Gradient Boosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.86      0.83      0.85        30\n",
            "         2.0       0.73      0.79      0.76        24\n",
            "         3.0       0.65      0.63      0.64        38\n",
            "         4.0       0.68      0.68      0.68        31\n",
            "\n",
            "    accuracy                           0.72       123\n",
            "   macro avg       0.73      0.73      0.73       123\n",
            "weighted avg       0.72      0.72      0.72       123\n",
            "\n",
            "Gradient Boosting Confusion Matrix:\n",
            "[[25  3  2  0]\n",
            " [ 3 19  2  0]\n",
            " [ 1  3 24 10]\n",
            " [ 0  1  9 21]]\n",
            "SVM Accuracy: 0.7236\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.82      0.90      0.86        30\n",
            "         2.0       0.68      0.79      0.73        24\n",
            "         3.0       0.71      0.53      0.61        38\n",
            "         4.0       0.68      0.74      0.71        31\n",
            "\n",
            "    accuracy                           0.72       123\n",
            "   macro avg       0.72      0.74      0.73       123\n",
            "weighted avg       0.72      0.72      0.72       123\n",
            "\n",
            "SVM Confusion Matrix:\n",
            "[[27  3  0  0]\n",
            " [ 3 19  2  0]\n",
            " [ 3  4 20 11]\n",
            " [ 0  2  6 23]]\n",
            "Logistic Regression Accuracy: 0.7154\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.82      0.93      0.87        30\n",
            "         2.0       0.73      0.79      0.76        24\n",
            "         3.0       0.67      0.47      0.55        38\n",
            "         4.0       0.64      0.74      0.69        31\n",
            "\n",
            "    accuracy                           0.72       123\n",
            "   macro avg       0.71      0.74      0.72       123\n",
            "weighted avg       0.71      0.72      0.71       123\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[28  2  0  0]\n",
            " [ 3 19  2  0]\n",
            " [ 3  4 18 13]\n",
            " [ 0  1  7 23]]\n",
            "Naive Bayes Accuracy: 0.7073\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.86      0.83      0.85        30\n",
            "         2.0       0.61      0.79      0.69        24\n",
            "         3.0       0.69      0.53      0.60        38\n",
            "         4.0       0.68      0.74      0.71        31\n",
            "\n",
            "    accuracy                           0.71       123\n",
            "   macro avg       0.71      0.72      0.71       123\n",
            "weighted avg       0.71      0.71      0.70       123\n",
            "\n",
            "Naive Bayes Confusion Matrix:\n",
            "[[25  4  1  0]\n",
            " [ 3 19  2  0]\n",
            " [ 1  6 20 11]\n",
            " [ 0  2  6 23]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import KMeansSMOTE  # Import KMeansSMOTE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier  # Already included in RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # Import LDA\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/dataset-data-class.csv')\n",
        "\n",
        "# Handle missing values (optional)\n",
        "data = data.dropna()  # Remove rows with missing values (consider imputation if necessary)\n",
        "\n",
        "data = data.drop(columns=['column_to_drop'], errors='ignore')\n",
        "\n",
        "# Select only numerical columns\n",
        "numerical_data = data.select_dtypes(include=['int', 'float'])\n",
        "data = numerical_data\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "y = data['severity']  # Assuming 'severity' is your target column\n",
        "X = data.drop('severity', axis=1)  # Drop 'severity' from features\n",
        "\n",
        "# Class distribution before KMeansSMOTE (optional)\n",
        "class_distribution_before = y.value_counts().sort_values(ascending=False)\n",
        "print(\"Class Distribution Before KMeansSMOTE:\\n\", class_distribution_before)\n",
        "\n",
        "# Apply KMeansSMOTE to balance classes with sampling_strategy='all'\n",
        "kmeans_smote = KMeansSMOTE(sampling_strategy='all',\n",
        "                           cluster_balance_threshold=0.1,  # Lower cluster balance threshold\n",
        "                           k_neighbors=5,  # Number of nearest neighbors for SMOTE\n",
        "                           random_state=42)\n",
        "X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
        "\n",
        "# Class distribution after KMeansSMOTE (optional)\n",
        "class_distribution_after = y_resampled.value_counts().sort_values(ascending=False)\n",
        "print(\"Class Distribution After KMeansSMOTE:\\n\", class_distribution_after)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply LDA for dimensionality reduction\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "X_train_reduced = lda.fit_transform(X_train, y_train)\n",
        "X_test_reduced = lda.transform(X_test)\n",
        "\n",
        "# Print the number of features remaining after LDA\n",
        "num_features_after_lda = X_train_reduced.shape[1]\n",
        "print(f\"Number of features remaining after LDA: {num_features_after_lda}\")\n",
        "\n",
        "# Define and train models (using reduced features)\n",
        "models = {\n",
        "    \"KNN (3 neighbors)\": KNeighborsClassifier(n_neighbors=3),\n",
        "    \"KNN (5 neighbors)\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"SVM\": SVC(probability=True),  # Enable probability estimates for metrics\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_reduced, y_train)\n",
        "\n",
        "    # Make predictions on the test set (using reduced features)\n",
        "    y_pred = model.predict(X_test_reduced)\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Classification report (precision, recall, F1-score for each class)\n",
        "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(f\"{name} Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5AYiQ1jZplv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
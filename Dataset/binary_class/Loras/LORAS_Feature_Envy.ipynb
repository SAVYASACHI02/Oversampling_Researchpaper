{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjrDsUGz552z",
    "outputId": "63887e83-ea86-4fd2-e8be-f9fdc7d4909e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before Oversampling:\n",
      " severity\n",
      "1    280\n",
      "3     95\n",
      "2     23\n",
      "4     22\n",
      "Name: count, dtype: int64\n",
      "Class Distribution After Oversampling:\n",
      " severity\n",
      "1    280\n",
      "2    280\n",
      "3    280\n",
      "4    280\n",
      "Name: count, dtype: int64\n",
      "Number of features remaining after LDA: 3\n",
      "KNN (3 neighbors) Accuracy: 0.8571\n",
      "KNN (3 neighbors) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.88      0.79        58\n",
      "           2       0.96      0.88      0.92        57\n",
      "           3       0.84      0.74      0.79        62\n",
      "           4       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.86       224\n",
      "   macro avg       0.87      0.86      0.87       224\n",
      "weighted avg       0.87      0.86      0.86       224\n",
      "\n",
      "KNN (3 neighbors) Confusion Matrix:\n",
      "[[51  1  6  0]\n",
      " [ 5 50  2  0]\n",
      " [14  1 46  1]\n",
      " [ 1  0  1 45]]\n",
      "KNN (5 neighbors) Accuracy: 0.8125\n",
      "KNN (5 neighbors) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.69      0.70        58\n",
      "           2       0.91      0.86      0.88        57\n",
      "           3       0.73      0.77      0.75        62\n",
      "           4       0.96      0.96      0.96        47\n",
      "\n",
      "    accuracy                           0.81       224\n",
      "   macro avg       0.82      0.82      0.82       224\n",
      "weighted avg       0.81      0.81      0.81       224\n",
      "\n",
      "KNN (5 neighbors) Confusion Matrix:\n",
      "[[40  3 15  0]\n",
      " [ 4 49  3  1]\n",
      " [11  2 48  1]\n",
      " [ 2  0  0 45]]\n",
      "Random Forest Accuracy: 0.9866\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98        58\n",
      "           2       1.00      0.98      0.99        57\n",
      "           3       0.95      1.00      0.98        62\n",
      "           4       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           0.99       224\n",
      "   macro avg       0.99      0.99      0.99       224\n",
      "weighted avg       0.99      0.99      0.99       224\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      "[[56  0  2  0]\n",
      " [ 0 56  1  0]\n",
      " [ 0  0 62  0]\n",
      " [ 0  0  0 47]]\n",
      "AdaBoost Accuracy: 0.2634\n",
      "AdaBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.32      1.00      0.49        57\n",
      "           3       0.02      0.02      0.02        62\n",
      "           4       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.26       224\n",
      "   macro avg       0.34      0.26      0.14       224\n",
      "weighted avg       0.30      0.26      0.14       224\n",
      "\n",
      "AdaBoost Confusion Matrix:\n",
      "[[ 0 58  0  0]\n",
      " [ 0 57  0  0]\n",
      " [ 0 61  1  0]\n",
      " [ 0  0 46  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9821\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.98      0.99        58\n",
      "           2       1.00      0.96      0.98        57\n",
      "           3       0.95      0.98      0.97        62\n",
      "           4       0.98      1.00      0.99        47\n",
      "\n",
      "    accuracy                           0.98       224\n",
      "   macro avg       0.98      0.98      0.98       224\n",
      "weighted avg       0.98      0.98      0.98       224\n",
      "\n",
      "Gradient Boosting Confusion Matrix:\n",
      "[[57  0  1  0]\n",
      " [ 0 55  2  0]\n",
      " [ 0  0 61  1]\n",
      " [ 0  0  0 47]]\n",
      "SVM Accuracy: 0.3884\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.59      0.54        58\n",
      "           2       0.42      0.26      0.32        57\n",
      "           3       0.00      0.00      0.00        62\n",
      "           4       0.32      0.81      0.46        47\n",
      "\n",
      "    accuracy                           0.39       224\n",
      "   macro avg       0.31      0.41      0.33       224\n",
      "weighted avg       0.30      0.39      0.32       224\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[34 10  1 13]\n",
      " [13 15  0 29]\n",
      " [12 11  0 39]\n",
      " [ 9  0  0 38]]\n",
      "Logistic Regression Accuracy: 0.5000\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.45      0.53        58\n",
      "           2       0.51      0.68      0.59        57\n",
      "           3       0.40      0.13      0.20        62\n",
      "           4       0.45      0.83      0.58        47\n",
      "\n",
      "    accuracy                           0.50       224\n",
      "   macro avg       0.50      0.52      0.47       224\n",
      "weighted avg       0.50      0.50      0.46       224\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[26 17  4 11]\n",
      " [ 8 39  1  9]\n",
      " [ 6 20  8 28]\n",
      " [ 1  0  7 39]]\n",
      "Naive Bayes Accuracy: 0.7768\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.67      0.79        58\n",
      "           2       0.59      0.96      0.73        57\n",
      "           3       0.85      0.53      0.65        62\n",
      "           4       0.94      1.00      0.97        47\n",
      "\n",
      "    accuracy                           0.78       224\n",
      "   macro avg       0.83      0.79      0.78       224\n",
      "weighted avg       0.83      0.78      0.77       224\n",
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[39 14  5  0]\n",
      " [ 1 55  1  0]\n",
      " [ 1 25 33  3]\n",
      " [ 0  0  0 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyloras import LORAS # Import LORA\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier  # Already included in RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('/content/dataset-feature-envy.csv')\n",
    "\n",
    "# Handle missing values (optional)\n",
    "data = data.dropna()  # Remove rows with missing values (consider imputation if necessary)\n",
    "\n",
    "data = data.drop(columns=['column_to_drop'], errors='ignore')\n",
    "\n",
    "# Select only numerical columns\n",
    "numerical_data = data.select_dtypes(include=['int', 'float'])\n",
    "data = numerical_data\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "y = data['severity']  # Assuming 'severity' is your target column\n",
    "X = data.drop('severity', axis=1)  # Drop 'severity' from features\n",
    "\n",
    "# Class distribution before SMOTE (optional)\n",
    "class_distribution_before = y.value_counts().sort_values(ascending=False)\n",
    "print(\"Class Distribution Before Oversampling:\\n\", class_distribution_before)\n",
    "\n",
    "# Apply LORAS for oversampling (assuming imbalanced data)\n",
    "oversample = LORAS()\n",
    "X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "\n",
    "# Class distribution after oversampling (optional)\n",
    "class_distribution_after = y_resampled.value_counts().sort_values(ascending=False)\n",
    "print(\"Class Distribution After Oversampling:\\n\", class_distribution_after)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train_reduced = lda.fit_transform(X_train, y_train)\n",
    "X_test_reduced = lda.transform(X_test)\n",
    "\n",
    "# Print the number of features remaining after LDA\n",
    "num_features_after_lda = X_train_reduced.shape[1]\n",
    "print(f\"Number of features remaining after LDA: {num_features_after_lda}\")\n",
    "\n",
    "# Define and train models\n",
    "models = {\n",
    "    \"KNN (3 neighbors)\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"KNN (5 neighbors)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC(probability=True),  # Enable probability estimates for metrics\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification report (precision, recall, F1-score for each class)\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(f\"{name} Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjQqJG4t-E6H",
    "outputId": "9e854aca-3ed3-4338-caad-fdcbce07ed22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyloras\n",
      "  Downloading pyloras-0.1.0b6-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from pyloras) (1.25.2)\n",
      "Requirement already satisfied: imbalanced-learn<1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyloras) (0.10.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn<1.0.0->pyloras) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn<1.0.0->pyloras) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn<1.0.0->pyloras) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn<1.0.0->pyloras) (3.4.0)\n",
      "Installing collected packages: pyloras\n",
      "Successfully installed pyloras-0.1.0b6\n"
     ]
    }
   ],
   "source": [
    "! pip install -U pyloras"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
